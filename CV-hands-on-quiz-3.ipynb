{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef69e825-fba4-4f7a-b9f6-eb3bb889aa45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the training images from the path and labelling them into the given categories\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 # this is an important module to get imported which may even cause issues while reading the data if not used\n",
    "import os\n",
    "import seaborn as sns # for data visualization \n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.models import Sequential #sequential api for sequential model \n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten #importing different layers \n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Activation, Input, LeakyReLU,Activation\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical #to perform one-hot encoding \n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.optimizers import RMSprop,Adam #optimiers for optimizing the model\n",
    "from tensorflow.keras.callbacks import EarlyStopping  #regularization method to prevent the overfitting\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras import losses, optimizers\n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa3430ae-c78d-46b4-bb59-adc3ca4592e4",
   "metadata": {
    "id": "rOIuj9WlOkNJ"
   },
   "outputs": [],
   "source": [
    "# Storing the training path in a variable named DATADIR, and storing the unique categories/labels in a list\n",
    "\n",
    "DATADIR = \"./shapes/Training\"                                             # Path of training data after unzipping\n",
    "CATEGORIES = [\"circles\",\"squares\",\"triangles\"]  # Storing all the categories in categories variable\n",
    "IMG_SIZE=28                                                                   # Defining the size of the image to 150    \n",
    "                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58228daf-d923-4701-9e81-8d14760a167a",
   "metadata": {
    "id": "d3gLIZA_2mma"
   },
   "outputs": [],
   "source": [
    "# Here we will be using a user defined function create_training_data() to extract the images from the directory\n",
    "training_data = []                                                             # Storing all the training images\n",
    "def create_training_data():\n",
    "    for category in CATEGORIES:                                                # Looping over each category from the CATEGORIES list\n",
    "        path = os.path.join(DATADIR,category)                                  # Joining images with labels\n",
    "        class_num = category                                                   \n",
    "        for img in os.listdir(path):                                           \n",
    "          img_array = cv2.imread(os.path.join(path,img),cv2.IMREAD_GRAYSCALE)  # Converting image to greyscale to reduce the complexity and computation \n",
    "          new_array = cv2.resize(img_array,(IMG_SIZE,IMG_SIZE))                # Resizing the images \n",
    "          training_data.append([new_array,class_num])                          # Appending both the images and labels\n",
    "create_training_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f035c5d8-ab4a-496f-9e00-fc52a81761dc",
   "metadata": {
    "id": "aOzq2maeXxUg"
   },
   "source": [
    "### **Reading the Testing Dataset**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1807aa93-c7bf-45ce-945a-fdf595502416",
   "metadata": {
    "id": "Hjy4-7uLP2PD"
   },
   "outputs": [],
   "source": [
    "DATADIR_test = \"./shapes/Testing\"                                         # Path of testing data after unzipping\n",
    "CATEGORIES = [\"circles\",\"squares\",\"triangles\"]  # Storing all the categories in categories variable\n",
    "IMG_SIZE=28                                                                   # Defining the size of the image to 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d257fe9c-b52b-4f44-aba4-ed2fa467e26a",
   "metadata": {
    "id": "HO7Wo6jHWkE_"
   },
   "outputs": [],
   "source": [
    "# Here we will be using a user defined function create_testing_data() to extract the images from the directory\n",
    "testing_data = []\n",
    "\n",
    "def create_testing_data():                                                     # Storing all the testing images\n",
    "    for category in CATEGORIES:                                                # Looping over each category from the CATEGORIES list\n",
    "        path = os.path.join(DATADIR_test,category)                             # Joining images with labels     \n",
    "        class_num = category\n",
    "        for img in os.listdir(path):                                           \n",
    "          img_array = cv2.imread(os.path.join(path,img),cv2.IMREAD_GRAYSCALE)  # Converting image to greyscale to reduce the complexity and computation \n",
    "          new_array = cv2.resize(img_array,(IMG_SIZE,IMG_SIZE))                # Resizing the images\n",
    "          testing_data.append([new_array,class_num])                           # Appending both the images and labels\n",
    "\n",
    "create_testing_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4170cf29-0392-4f69-a844-ea0c03fd7472",
   "metadata": {
    "id": "Z7vzDL7yQqyh"
   },
   "source": [
    "**Let's visualize MRI images randomly from each of the four classes.** \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a545b670-753f-4792-a4b8-0210e60a268b",
   "metadata": {
    "id": "BRfPP-hi1mat"
   },
   "outputs": [],
   "source": [
    "# Creating 4 different lists to store the image names for each category by reading them from their respective directories. \n",
    "circles = [fn for fn in os.listdir(f'{DATADIR}/{CATEGORIES[0]}') ]    # Looping over the path of each image from the glioma_tumor directory\n",
    "squares = [fn for fn in os.listdir(f'{DATADIR}/{CATEGORIES[1]}')]     # Looping over the path of each image from the meningioma_tumor directory\n",
    "triangles = [fn for fn in os.listdir(f'{DATADIR}/{CATEGORIES[2]}') ]  # Looping over the path of each image from the no_tumor directory\n",
    "\n",
    "\n",
    "# Ranodmly selecting 3 images from each category\n",
    "select_cir = np.random.choice(circles, 3, replace = False)               \n",
    "select_sq = np.random.choice(squares, 3, replace = False)\n",
    "select_tr = np.random.choice(triangles, 3, replace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a71b56f1-2ff6-4f67-b9a1-c8db3ab06dbe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 591
    },
    "id": "IdqDkn4w1v7J",
    "outputId": "77d8237f-5c57-4a78-b9fb-fc19a46f60ee"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# plotting 4 x 3 image matrix\n",
    "fig = plt.figure(figsize = (10,10))\n",
    "\n",
    "# Plotting three images from each of the four categories by looping through their path \n",
    "for i in range(9):\n",
    "    if i < 3:\n",
    "        fp = f'{DATADIR}/{CATEGORIES[0]}/{select_cir[i]}'  # Here datadir is a path to the training data and categories[0] indicate the first label galioma tumor and here we are looping over to take the three random images that we have stored in select_galo variable \n",
    "        label = 'Circle'                                   \n",
    "    if i>=3 and i<6:\n",
    "        fp = f'{DATADIR}/{CATEGORIES[1]}/{select_sq[i-3]}'  # Here datadir is a path to the training data and categories[1] indicate the second label meningioma tumor and here we are looping over to take the three random images that we have stored in select_menin variable \n",
    "        label = 'Square' \n",
    "    if i>=6 and i<9:\n",
    "        fp = f'{DATADIR}/{CATEGORIES[2]}/{select_tr[i-6]}'   # Here datadir is a path to the training data and categories[2] indicate the third label no tumor and here we are looping over to take the three random images that we have stored in select_no_t variable \n",
    "        label = 'Triangle'\n",
    "    ax = fig.add_subplot(3, 3, i+1)\n",
    "    \n",
    "    # Plotting each image using load_img function\n",
    "    fn = image.load_img(fp, target_size = (28,28), color_mode='grayscale')\n",
    "    plt.imshow(fn, cmap='Greys_r')\n",
    "    plt.title(label)\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3cee17-636f-4fcc-9ed4-d6ed04c936d2",
   "metadata": {
    "id": "Wxmm9eZPYKEw"
   },
   "source": [
    "### **Data Preprocessing** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "762de0a6-3f78-4f74-a9d8-d48c77d3f9d2",
   "metadata": {
    "id": "bSfeBdl527nK"
   },
   "outputs": [],
   "source": [
    "# Creating two different lists to store the Numpy arrays and the corresponding labels\n",
    "X_train = []                                                                   \n",
    "y_train = []\n",
    "np.random.shuffle(training_data)          # Shuffling data to reduce variance and making sure that model remains general and overfit less\n",
    "for features,label in training_data:      # Iterating over the training data which is generated from the create_training_data() function \n",
    "    X_train.append(features)              # Appending images into X_train\n",
    "    y_train.append(label)                 # Appending labels into y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cf1336e-960f-4a60-a971-8c4b438747b2",
   "metadata": {
    "id": "bVEJpQuaYw72"
   },
   "outputs": [],
   "source": [
    "# Creating two different lists to store the Numpy arrays and the corresponding labels\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "np.random.shuffle(testing_data)          # Shuffling data to reduce variance and making sure that model remains general and overfit less\n",
    "for features,label in testing_data:      # Iterating over the training data which is generated from the create_testing_data() function\n",
    "    X_test.append(features)              # Appending images into X_train\n",
    "    y_test.append(label)                 # Appending labels into y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "beb88a5a-5a25-4cea-bc0f-4fe94df4408d",
   "metadata": {
    "id": "jCtaXu_iO3XS"
   },
   "outputs": [],
   "source": [
    "# Converting the list into DataFrame\n",
    "y_train = pd.DataFrame(y_train, columns=[\"Label\"],dtype=object) \n",
    "y_test = pd.DataFrame(y_test, columns=[\"Label\"],dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08c379cd-e896-4eaf-bd75-eb6fde492f3d",
   "metadata": {
    "id": "oOGvpyf42acL"
   },
   "outputs": [],
   "source": [
    "# Converting the pixel values into Numpy array\n",
    "X_train= np.array(X_train) \n",
    "X_test= np.array(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed4f97a4-7483-4276-9975-e18aff6e5f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalizing the image data \n",
    "X_train= X_train/255.0\n",
    "X_test = X_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d28f06f9-693a-47f5-bf9e-effa457fbcad",
   "metadata": {
    "id": "58dRjnj7VcHz"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "# Storing the LabelBinarizer function in lb variable\n",
    "lb = LabelBinarizer() \n",
    "# Applying fit_transform on train target variable\n",
    "y_train_e = lb.fit_transform(y_train)\n",
    "# Applying only transform on test target variable\n",
    "y_test_e = lb.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6035680-b28d-49c1-8803-39ea4f23fa2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(1)\n",
    "np.random.seed(1) \n",
    "tf.random.set_seed(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27fb82c2-10d3-47c5-b0be-f2333747b9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-19 22:28:52.422020: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(64, 3, activation=\"relu\", padding=\"same\", input_shape=[28,28,1]))\n",
    "model.add(MaxPooling2D(2))\n",
    "model.add(Conv2D(128, 3, activation=\"relu\", padding=\"same\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64,activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32,activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation=\"softmax\"))\n",
    "optimizer = Adam()\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "704848ba-4d10-4357-8b0b-b8c2c398076a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "7/7 [==============================] - 1s 61ms/step - loss: 1.2564 - accuracy: 0.2917 - val_loss: 1.1006 - val_accuracy: 0.2917\n",
      "Epoch 2/30\n",
      "7/7 [==============================] - 0s 37ms/step - loss: 1.0980 - accuracy: 0.3565 - val_loss: 1.1000 - val_accuracy: 0.2917\n",
      "Epoch 3/30\n",
      "7/7 [==============================] - 0s 38ms/step - loss: 1.0998 - accuracy: 0.3102 - val_loss: 1.0996 - val_accuracy: 0.2917\n",
      "Epoch 4/30\n",
      "7/7 [==============================] - 0s 38ms/step - loss: 1.0996 - accuracy: 0.3287 - val_loss: 1.0986 - val_accuracy: 0.2917\n",
      "Epoch 5/30\n",
      "7/7 [==============================] - 0s 38ms/step - loss: 1.0988 - accuracy: 0.3287 - val_loss: 1.0988 - val_accuracy: 0.2917\n",
      "Epoch 6/30\n",
      "7/7 [==============================] - 0s 37ms/step - loss: 1.0987 - accuracy: 0.3380 - val_loss: 1.0987 - val_accuracy: 0.2917\n",
      "Epoch 7/30\n",
      "7/7 [==============================] - 0s 38ms/step - loss: 1.0986 - accuracy: 0.3380 - val_loss: 1.0988 - val_accuracy: 0.2917\n",
      "Epoch 8/30\n",
      "7/7 [==============================] - 0s 39ms/step - loss: 1.0988 - accuracy: 0.3380 - val_loss: 1.0994 - val_accuracy: 0.2917\n",
      "Epoch 9/30\n",
      "7/7 [==============================] - 0s 40ms/step - loss: 1.0987 - accuracy: 0.3380 - val_loss: 1.0997 - val_accuracy: 0.2917\n",
      "Epoch 10/30\n",
      "7/7 [==============================] - 0s 39ms/step - loss: 1.0987 - accuracy: 0.3380 - val_loss: 1.1000 - val_accuracy: 0.2917\n",
      "Epoch 11/30\n",
      "7/7 [==============================] - 0s 39ms/step - loss: 1.0986 - accuracy: 0.3380 - val_loss: 1.1003 - val_accuracy: 0.2917\n",
      "Epoch 12/30\n",
      "7/7 [==============================] - 0s 39ms/step - loss: 1.0986 - accuracy: 0.3380 - val_loss: 1.1003 - val_accuracy: 0.2917\n",
      "Epoch 13/30\n",
      "7/7 [==============================] - 0s 39ms/step - loss: 1.0986 - accuracy: 0.3380 - val_loss: 1.1009 - val_accuracy: 0.2917\n",
      "Epoch 14/30\n",
      "7/7 [==============================] - 0s 38ms/step - loss: 1.0986 - accuracy: 0.3380 - val_loss: 1.1010 - val_accuracy: 0.2917\n",
      "Epoch 15/30\n",
      "7/7 [==============================] - 0s 38ms/step - loss: 1.0981 - accuracy: 0.3380 - val_loss: 1.1012 - val_accuracy: 0.2917\n",
      "Epoch 16/30\n",
      "7/7 [==============================] - 0s 38ms/step - loss: 1.0981 - accuracy: 0.3380 - val_loss: 1.1015 - val_accuracy: 0.2917\n",
      "Epoch 17/30\n",
      "7/7 [==============================] - 0s 39ms/step - loss: 1.0989 - accuracy: 0.3380 - val_loss: 1.1016 - val_accuracy: 0.2917\n",
      "Epoch 18/30\n",
      "7/7 [==============================] - 0s 39ms/step - loss: 1.0990 - accuracy: 0.3380 - val_loss: 1.1016 - val_accuracy: 0.2917\n",
      "Epoch 19/30\n",
      "7/7 [==============================] - 0s 39ms/step - loss: 1.0987 - accuracy: 0.3472 - val_loss: 1.1016 - val_accuracy: 0.2917\n",
      "Epoch 20/30\n",
      "7/7 [==============================] - 0s 40ms/step - loss: 1.0987 - accuracy: 0.3426 - val_loss: 1.1019 - val_accuracy: 0.2917\n",
      "Epoch 21/30\n",
      "7/7 [==============================] - 0s 42ms/step - loss: 1.0984 - accuracy: 0.3194 - val_loss: 1.1021 - val_accuracy: 0.2917\n",
      "Epoch 22/30\n",
      "7/7 [==============================] - 0s 46ms/step - loss: 1.0982 - accuracy: 0.3333 - val_loss: 1.1025 - val_accuracy: 0.2917\n",
      "Epoch 23/30\n",
      "7/7 [==============================] - 0s 47ms/step - loss: 1.0982 - accuracy: 0.3102 - val_loss: 1.1029 - val_accuracy: 0.2917\n",
      "Epoch 24/30\n",
      "7/7 [==============================] - 0s 46ms/step - loss: 1.0988 - accuracy: 0.3102 - val_loss: 1.1032 - val_accuracy: 0.2917\n",
      "Epoch 25/30\n",
      "7/7 [==============================] - 0s 39ms/step - loss: 1.0981 - accuracy: 0.3287 - val_loss: 1.1034 - val_accuracy: 0.2917\n",
      "Epoch 26/30\n",
      "7/7 [==============================] - 0s 40ms/step - loss: 1.0980 - accuracy: 0.3241 - val_loss: 1.1036 - val_accuracy: 0.2917\n",
      "Epoch 27/30\n",
      "7/7 [==============================] - 0s 41ms/step - loss: 1.0978 - accuracy: 0.3333 - val_loss: 1.1039 - val_accuracy: 0.2917\n",
      "Epoch 28/30\n",
      "7/7 [==============================] - 0s 45ms/step - loss: 1.0981 - accuracy: 0.3565 - val_loss: 1.1041 - val_accuracy: 0.2917\n",
      "Epoch 29/30\n",
      "7/7 [==============================] - 0s 44ms/step - loss: 1.0990 - accuracy: 0.3102 - val_loss: 1.1043 - val_accuracy: 0.2917\n",
      "Epoch 30/30\n",
      "7/7 [==============================] - 0s 42ms/step - loss: 1.0981 - accuracy: 0.3611 - val_loss: 1.1044 - val_accuracy: 0.2917\n"
     ]
    }
   ],
   "source": [
    "# classifier.fit(\n",
    "#     normalized_ds,\n",
    "#     # steps_per_epoch = int(240/32),\n",
    "#     epochs = 100,\n",
    "#     validation_data = normalized_val_ds,\n",
    "#     # validation_steps = int(60/32),\n",
    "#     # validation_split=0.2, \n",
    "#     batch_size=batch_size, \n",
    "#     callbacks=[es], \n",
    "#     verbose=1,\n",
    "#     # class_weight=class_weights\n",
    "# )\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, \n",
    "    y_train_e, \n",
    "    validation_split=0.1, \n",
    "    batch_size=32,\n",
    "    epochs=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ddfa668-b19c-482b-95b6-53b17f137e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 9ms/step - loss: 1.0988 - accuracy: 0.3333\n"
     ]
    }
   ],
   "source": [
    "acc=model.evaluate(X_test,np.array(y_test_e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90049413-eaf1-4555-8251-6a1fd0b6a42a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
